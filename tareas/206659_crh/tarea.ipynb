{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lancedb\n",
    "import pyarrow as pa\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este ejercicio descargamos una base de datos de mensajes de texto en inglés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"chirunder/text_messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top right I gained a little speed with the add...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They are heavier wheels though as are all the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Federally registering a trademark is more than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'll have to jog my memory from rooting a few ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unless you can afford to buy all new larger cl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texto\n",
       "0  Top right I gained a little speed with the add...\n",
       "1  They are heavier wheels though as are all the ...\n",
       "2  Federally registering a trademark is more than...\n",
       "3  I'll have to jog my memory from rooting a few ...\n",
       "4  Unless you can afford to buy all new larger cl..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset['train'])\n",
    "df.rename(columns={'text': 'texto'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para los siguientes ejercicios, voy a crear una variable del numero de palabras en cada mensaje de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>Top right I gained a little speed with the add...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>They are heavier wheels though as are all the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>Federally registering a trademark is more than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>I'll have to jog my memory from rooting a few ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Unless you can afford to buy all new larger cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>4</td>\n",
       "      <td>Just thrilled for you!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>12</td>\n",
       "      <td>I will be happy when the mornings are a little...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>9</td>\n",
       "      <td>haha the irony of me having nice nuts LOOL.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>11</td>\n",
       "      <td>It is going the way of MySpace, Geocities and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>23</td>\n",
       "      <td>I'm loving the verdigris on your guys, that co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      n                                              texto\n",
       "0    13  Top right I gained a little speed with the add...\n",
       "1    14  They are heavier wheels though as are all the ...\n",
       "2     9  Federally registering a trademark is more than...\n",
       "3    21  I'll have to jog my memory from rooting a few ...\n",
       "4    10  Unless you can afford to buy all new larger cl...\n",
       "..   ..                                                ...\n",
       "495   4                             Just thrilled for you!\n",
       "496  12  I will be happy when the mornings are a little...\n",
       "497   9        haha the irony of me having nice nuts LOOL.\n",
       "498  11  It is going the way of MySpace, Geocities and ...\n",
       "499  23  I'm loving the verdigris on your guys, that co...\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['n'] = df['texto'].apply(lambda x: len(str(x).split()))\n",
    "df = df[['n', 'texto']]\n",
    "df = df.head(500)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1:\n",
    "A partir del dataframe df, crea df_tokenized (usando el Tokenizer de GPT2) con dos columnas pero con el texto tokenizado. Asegurate de que todos los embeddings tengan la misma longitud y los tokens sean enteros (todos enteros o todos doubles). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                vector   n\n",
      "0    [9126, 826, 314, 8618, 257, 1310, 2866, 351, 2...  13\n",
      "1    [2990, 389, 20140, 13666, 996, 355, 389, 477, ...  14\n",
      "2    [37, 5702, 453, 28336, 257, 16028, 318, 517, 6...   9\n",
      "3    [40, 1183, 423, 284, 48342, 616, 4088, 422, 40...  21\n",
      "4    [28042, 345, 460, 5368, 284, 2822, 477, 649, 4...  10\n",
      "..                                                 ...  ..\n",
      "495  [5703, 20536, 329, 345, 0, 0, 0, 0, 0, 0, 0, 0...   4\n",
      "496  [40, 481, 307, 3772, 618, 262, 31143, 389, 257...  12\n",
      "497  [71, 12236, 262, 21296, 286, 502, 1719, 3621, ...   9\n",
      "498  [1026, 318, 1016, 262, 835, 286, 2011, 14106, ...  11\n",
      "499  [40, 1101, 14442, 262, 3326, 12894, 2442, 319,...  23\n",
      "\n",
      "[500 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2089/620747418.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tokenized['vector'] = df_tokenized['vector'].apply(lambda x: x[:300] + [0] * (300 - len(x)) if len(x) < 300 else x[:300])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cargar el tokenizer del modelo gpt2 de Huggingface\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Supongamos que tu DataFrame original se llama df y tiene dos columnas: 'texto' y 'n'\n",
    "\n",
    "# Tokenizar la columna de texto\n",
    "df['vector'] = df['texto'].apply(lambda x: tokenizer(x)[\"input_ids\"])\n",
    "\n",
    "# Convertir la columna de enteros a strings\n",
    "#df['n'] = df['n'].astype(str)\n",
    "\n",
    "# Tokenizar la columna convertida a strings\n",
    "#df['n_tokenized'] = df['n'].apply(lambda x: tokenizer(x)[\"input_ids\"])\n",
    "\n",
    "# Crear un nuevo DataFrame con las columnas tokenizadas\n",
    "df_tokenized = df[['vector', 'n']]\n",
    "df_tokenized['vector'] = df_tokenized['vector'].apply(lambda x: x[:300] + [0] * (300 - len(x)) if len(x) < 300 else x[:300])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Mostrar el nuevo DataFrame tokenizado\n",
    "print(df_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2:\n",
    "Mete el dataframe a una tabla en una base de datos de LanceDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyarrow.Table\n",
       "vector: fixed_size_list<item: float>[300]\n",
       "  child 0, item: float\n",
       "n: int64\n",
       "----\n",
       "vector: [[[9126,826,314,8618,257,...,0,0,0,0,0],[2990,389,20140,13666,996,...,0,0,0,0,0],[37,5702,453,28336,257,...,0,0,0,0,0],[40,1183,423,284,48342,...,0,0,0,0,0],[28042,345,460,5368,284,...,0,0,0,0,0]]]\n",
       "n: [[13,14,9,21,10]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nos conectamos a una base de datos local\n",
    "db = lancedb.connect(\"./.lancedb\")\n",
    "# Creamos una tabla en la base de datos\n",
    "if \"tabla\" in db.table_names():\n",
    "    db.drop_table(\"tabla\")\n",
    "db.create_table(\"tabla\", df_tokenized)\n",
    "db[\"tabla\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3:\n",
    "Haz una query estilo SQL a la tabla de la base de datos. Quiero que escribas la query equivalente y pongas la explicación de lo que está haciendo la consulta. Hint: usa la columna \"n\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vector</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[5195.0, 41320.0, 2767.0, 30.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[40732.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[7376.0, 364.0, 8518.0, 13.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[34.0, 5691.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[10814.0, 15744.0, 260.0, 13.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[38.0, 83.0, 6513.0, 612.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[39507.0, 2087.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[56.0, 18213.0, 45108.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[38052.0, 1342.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[37.0, 415.0, 3477.0, 1705.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              vector  n\n",
       "0  [5195.0, 41320.0, 2767.0, 30.0, 0.0, 0.0, 0.0,...  2\n",
       "1  [40732.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  1\n",
       "2  [7376.0, 364.0, 8518.0, 13.0, 0.0, 0.0, 0.0, 0...  2\n",
       "3  [34.0, 5691.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  1\n",
       "4  [10814.0, 15744.0, 260.0, 13.0, 0.0, 0.0, 0.0,...  2\n",
       "5  [38.0, 83.0, 6513.0, 612.0, 0.0, 0.0, 0.0, 0.0...  2\n",
       "6  [39507.0, 2087.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0....  2\n",
       "7  [56.0, 18213.0, 45108.0, 0.0, 0.0, 0.0, 0.0, 0...  2\n",
       "8  [38052.0, 1342.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0....  2\n",
       "9  [37.0, 415.0, 3477.0, 1705.0, 0.0, 0.0, 0.0, 0...  2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resuelve el task 3 aqui\n",
    "(db[\"tabla\"].search()\n",
    "    .where(\"n < 3\")\n",
    "    .select([\"vector\", \"n\"])\n",
    "    .limit(10)\n",
    "    .to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Query en SQL equivalente:\n",
    "\n",
    "SELECT texto, vector, n\n",
    "\n",
    "FROM tabla\n",
    "\n",
    "WHERE n < 3\n",
    "\n",
    "LIMIT 10;\n",
    "- Explicacion: Busca aquellos mensajes de la tabla que tengan menos de 3 palabras, regresa el texto, el texto tokenizado que es el vector y su longitud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4:\n",
    "Inventa un mensaje de texto que tu podrías escribirle a un amigo. Tokenizalo y ponlo en el formato adecuado para hacer un vector query. Quiero que me regreses el mensaje más parecido al mensaje que inventaste (OJO: quiero el texto, no el embedding). HINT: Hay que decodear el resultado del query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 1842, 345]\n",
      "[40, 1842, 345, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Resuelve el task 4 aqui\n",
    "mensaje = \"I love you\"\n",
    "mensaje_tokenized = tokenizer(mensaje)[\"input_ids\"]\n",
    "print(mensaje_tokenized)\n",
    "\n",
    "n = 300\n",
    "def ajustar_vector(input, n):\n",
    "    output = input[:n]\n",
    "    \n",
    "    # Si la lista es más corta que el tamaño objetivo, rellenar con 0.0\n",
    "    while len(output) < n:\n",
    "        output.append(0)\n",
    "    \n",
    "    return output\n",
    "mensaje_tokenized = ajustar_vector(mensaje_tokenized, n)\n",
    "\n",
    "print(mensaje_tokenized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mensajes = (db[\"tabla\"].search(mensaje_tokenized)\n",
    "    .metric(\"cosine\") # Puede ser L2 o cosine\n",
    "    .select([\"vector\", \"n\"])\n",
    "    .limit(10)\n",
    "    .to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mensaje más parecido a I love you es:  I doubt they will.!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Quitando los tokens 0:  I doubt they will.\n"
     ]
    }
   ],
   "source": [
    "mensaje_mas_parecido = mensajes['vector'][0]\n",
    "\n",
    "mensaje_decodificado = tokenizer.decode(mensaje_mas_parecido, skip_special_tokens=True)\n",
    "print(\"El mensaje más parecido a I love you es: \", mensaje_decodificado)\n",
    "\n",
    "mensaje_filtrado = [token for token in mensaje_mas_parecido if token != 0]\n",
    "mensaje_decodificado = tokenizer.decode(mensaje_filtrado,skip_special_tokens=True)\n",
    "print(\"Quitando los tokens 0: \", mensaje_decodificado)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
