{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lancedb\n",
    "import pyarrow as pa\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este ejercicio descargamos una base de datos de mensajes de texto en inglés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 451/451 [00:00<00:00, 627kB/s]\n",
      "Downloading data: 100%|██████████| 282M/282M [01:08<00:00, 4.09MB/s] \n",
      "Downloading data: 100%|██████████| 282M/282M [01:15<00:00, 3.75MB/s] \n",
      "Generating train split: 100%|██████████| 11615290/11615290 [00:21<00:00, 549933.03 examples/s] \n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"chirunder/text_messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top right I gained a little speed with the add...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They are heavier wheels though as are all the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Federally registering a trademark is more than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'll have to jog my memory from rooting a few ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unless you can afford to buy all new larger cl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texto\n",
       "0  Top right I gained a little speed with the add...\n",
       "1  They are heavier wheels though as are all the ...\n",
       "2  Federally registering a trademark is more than...\n",
       "3  I'll have to jog my memory from rooting a few ...\n",
       "4  Unless you can afford to buy all new larger cl..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset['train'])\n",
    "df.rename(columns={'text': 'texto'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para los siguientes ejercicios, voy a crear una variable del numero de palabras en cada mensaje de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>Top right I gained a little speed with the add...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>They are heavier wheels though as are all the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>Federally registering a trademark is more than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>I'll have to jog my memory from rooting a few ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Unless you can afford to buy all new larger cl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n                                              texto\n",
       "0  13  Top right I gained a little speed with the add...\n",
       "1  14  They are heavier wheels though as are all the ...\n",
       "2   9  Federally registering a trademark is more than...\n",
       "3  21  I'll have to jog my memory from rooting a few ...\n",
       "4  10  Unless you can afford to buy all new larger cl..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['n'] = df['texto'].apply(lambda x: len(str(x).split()))\n",
    "df = df[['n', 'texto']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1:\n",
    "A partir del dataframe df, crea df_tokenized (usando el Tokenizer de GPT2) con dos columnas pero con el texto tokenizado. Asegurate de que todos los embeddings tengan la misma longitud y los tokens sean enteros (todos enteros o todos doubles). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "mensajes_tokenizados = df['texto'].apply(lambda x: tokenizer(x)[\"input_ids\"])\n",
    "\n",
    "mensajes_tokenizados = mensajes_tokenizados.apply(lambda x: x[:200] + [0] * (200 - len(x)) if len(x) < 200 else x[:200])\n",
    "\n",
    "df_tokenized = pd.DataFrame({'vector': mensajes_tokenizados, 'name': df['n']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2:\n",
    "Mete el dataframe a una tabla en una base de datos de LanceDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = lancedb.connect(\"./mensajes.lancedb\")\n",
    "db.create_table(\"data\", df_tokenized)\n",
    "db[\"data\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3:\n",
    "Haz una query estilo SQL a la tabla de la base de datos. Quiero que escribas la query equivalente y pongas la explicación de lo que está haciendo la consulta. Hint: usa la columna \"n\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(db[\"data\"].search()\n",
    "    .where(\"texto LIKE '%going to take a nap%'\")\n",
    "    .select([\"name\", \"vector\"])\n",
    "    .limit(10)\n",
    "    .to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Query en SQL equivalente:\n",
    "- Explicacion: Busacos los 10 primeros mensajes que tengan el \"me voy a e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4:\n",
    "Inventa un mensaje de texto que tu podrías escribirle a un amigo. Tokenizalo y ponlo en el formato adecuado para hacer un vector query. Quiero que me regreses el mensaje más parecido al mensaje que inventaste (OJO: quiero el texto, no el embedding). HINT: Hay que decodear el resultado del query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mensaje = 'Floppy has been the best teacher of my career'\n",
    "mensaje = tokenizer(mensaje)[\"input_ids\"]\n",
    "\n",
    "menaje = mensaje.apply(lambda x: x[:200] + [0] * (200 - len(x)) if len(x) < 200 else x[:200])\n",
    "\n",
    "query = (db[\"data\"].search(mensaje)\n",
    "        .metric(\"cosine\")\n",
    "        .select([\"vector\"])\n",
    "        .limit(5)\n",
    "        .to_pandas())\n",
    "\n",
    "query_tokenizado = querry['vector'].values[0]\n",
    "\n",
    "mensaje_parecido =  tokenizer.decode(query_tokenizado, skip_special_tokens=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
