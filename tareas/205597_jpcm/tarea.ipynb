{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cord2108/miniconda3/envs/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import lancedb\n",
    "import pyarrow as pa\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este ejercicio descargamos una base de datos de mensajes de texto en inglés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"chirunder/text_messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset['train'])\n",
    "df.rename(columns={'text': 'texto'}, inplace=True)\n",
    "df = df.head(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para los siguientes ejercicios, voy a crear una variable del numero de palabras en cada mensaje de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>Top right I gained a little speed with the add...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>They are heavier wheels though as are all the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>Federally registering a trademark is more than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>I'll have to jog my memory from rooting a few ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Unless you can afford to buy all new larger cl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n                                              texto\n",
       "0  13  Top right I gained a little speed with the add...\n",
       "1  14  They are heavier wheels though as are all the ...\n",
       "2   9  Federally registering a trademark is more than...\n",
       "3  21  I'll have to jog my memory from rooting a few ...\n",
       "4  10  Unless you can afford to buy all new larger cl..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['n'] = df['texto'].apply(lambda x: len(str(x).split()))\n",
    "df = df[['n', 'texto']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1:\n",
    "A partir del dataframe df, crea df_tokenized (usando el Tokenizer de GPT2) con dos columnas pero con el texto tokenizado. Asegurate de que todos los embeddings tengan la misma longitud y los tokens sean enteros (todos enteros o todos doubles). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['n', 'texto', 'tokenized_text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Cargar el tokenizer del modelo GPT2 de Huggingface\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Función para tokenizar y ajustar la longitud a 300 tokens\n",
    "def tokenize_and_adjust_length(text):\n",
    "    tokenized_text = tokenizer(text)[\"input_ids\"]\n",
    "    if len(tokenized_text) < 300:\n",
    "        tokenized_text += [tokenizer.pad_token_id] * (300 - len(tokenized_text))\n",
    "    else:\n",
    "        tokenized_text = tokenized_text[:300]\n",
    "    return tokenized_text\n",
    "\n",
    "# Aplicar la tokenización al texto\n",
    "df['tokenized_text'] = df['texto'].apply(tokenize_and_adjust_length)\n",
    "print(df.columns)\n",
    "\n",
    "df_tokenized = pd.DataFrame({'vector': df['tokenized_text'], 'texto': df['texto'], \"n\": df['n']})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2:\n",
    "Mete el dataframe a una tabla en una base de datos de LanceDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyarrow.Table\n",
       "vector: fixed_size_list<item: float>[300]\n",
       "  child 0, item: float\n",
       "texto: string\n",
       "n: int64\n",
       "----\n",
       "vector: [[[9126,826,314,8618,257,...,50256,50256,50256,50256,50256],[2990,389,20140,13666,996,...,50256,50256,50256,50256,50256],[37,5702,453,28336,257,...,50256,50256,50256,50256,50256],[40,1183,423,284,48342,...,50256,50256,50256,50256,50256],[28042,345,460,5368,284,...,50256,50256,50256,50256,50256]]]\n",
       "texto: [[\"Top right I gained a little speed with the addition of IM heads.\",\"They are heavier wheels though as are all the CV concave line from Vossen.\",\"Federally registering a trademark is more than just aesthetics.\",\"I'll have to jog my memory from rooting a few weeks ago, but it was a simple step from that point.\",\"Unless you can afford to buy all new larger clothes!\"]]\n",
       "n: [[13,14,9,21,10]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nos conectamos a una base de datos local\n",
    "db = lancedb.connect(\"./.lancedb\")\n",
    "# Creamos una tabla en la base de datos\n",
    "db.create_table(\"tabla\", df_tokenized)\n",
    "db[\"tabla\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3:\n",
    "Haz una query estilo SQL a la tabla de la base de datos. Quiero que escribas la query equivalente y pongas la explicación de lo que está haciendo la consulta. Hint: usa la columna \"n\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     n                                             vector\n",
      "0   13  [9126.0, 826.0, 314.0, 8618.0, 257.0, 1310.0, ...\n",
      "1   14  [2990.0, 389.0, 20140.0, 13666.0, 996.0, 355.0...\n",
      "2    9  [37.0, 5702.0, 453.0, 28336.0, 257.0, 16028.0,...\n",
      "3   21  [40.0, 1183.0, 423.0, 284.0, 48342.0, 616.0, 4...\n",
      "4   10  [28042.0, 345.0, 460.0, 5368.0, 284.0, 2822.0,...\n",
      "5   12  [15784.0, 329.0, 257.0, 2524.0, 326.0, 318.0, ...\n",
      "6   24  [2949.0, 14148.0, 4001.0, 475.0, 345.0, 761.0,...\n",
      "7    4  [2990.0, 389.0, 16001.0, 19943.0, 13.0, 50256....\n",
      "8   15  [1858.0, 3729.0, 389.0, 517.0, 6792.0, 5672.0,...\n",
      "9   15  [1639.0, 3551.0, 880.0, 11.0, 290.0, 1944.0, 3...\n",
      "10  13  [464.0, 1097.0, 4444.0, 510.0, 852.0, 2861.0, ...\n"
     ]
    }
   ],
   "source": [
    "result_df = (\n",
    "    db[\"tabla\"].search()\n",
    "    .where(\"n > 3\")\n",
    "    .select([\"n\", \"vector\"])\n",
    "    .limit(11)\n",
    "    .to_pandas()\n",
    ")\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Query en SQL equivalente:\n",
    "- Explicacion: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select n, tokenized_text\n",
    "From tabla\n",
    "Where n > 3\n",
    "\n",
    "Estamos checando cuales son los textos con mas de tres palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4:\n",
    "Inventa un mensaje de texto que tu podrías escribirle a un amigo. Tokenizalo y ponlo en el formato adecuado para hacer un vector query. Quiero que me regreses el mensaje más parecido al mensaje que inventaste (OJO: quiero el texto, no el embedding). HINT: Hay que decodear el resultado del query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud del vector ajustado: 300\n",
      "Vector ajustado: [34094, 345, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n"
     ]
    }
   ],
   "source": [
    "# Cargar el tokenizer del modelo GPT2 de Huggingface\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Establecer el token de relleno\n",
    "\n",
    "# Mensaje de texto a tokenizar\n",
    "mensaje = \"Fuck you\"\n",
    "\n",
    "# Tokenizar el mensaje directamente con el tokenizer para obtener los 'input_ids'\n",
    "mensaje_tokenizado = tokenizer(mensaje)[\"input_ids\"]\n",
    "\n",
    "# Longitud deseada del vector\n",
    "longitud_deseada = 300\n",
    "\n",
    "def ajustar_vector(input_ids, longitud_deseada):\n",
    "    # Truncar si la lista es más larga que la longitud deseada\n",
    "    output = input_ids[:longitud_deseada]\n",
    "    # Rellenar con el ID del token de padding si es más corta\n",
    "    pad_token_id = tokenizer.pad_token_id\n",
    "    output += [pad_token_id] * (longitud_deseada - len(output))\n",
    "    return output\n",
    "\n",
    "# Ajustar el vector tokenizado a la longitud deseada\n",
    "mensaje_tokenizado_ajustado = ajustar_vector(mensaje_tokenizado, longitud_deseada)\n",
    "\n",
    "# Imprimir el resultado\n",
    "print(\"Longitud del vector ajustado:\", len(mensaje_tokenizado_ajustado))\n",
    "print(\"Vector ajustado:\", mensaje_tokenizado_ajustado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String generado a partir del embedding: Arizona?\n"
     ]
    }
   ],
   "source": [
    "result = (db[\"tabla\"].search(mensaje_tokenizado_ajustado)\n",
    " .metric(\"L2\") # Puede ser L2 o cosine\n",
    " .select([\"vector\"]) # Seleccionar la columna 'tokenized_text'\n",
    " .limit(1)\n",
    " .to_pandas())\n",
    "\n",
    "vector = result['vector'][0]\n",
    "\n",
    "original_string = tokenizer.decode(vector, skip_special_tokens=True)\n",
    "print(\"String generado a partir del embedding:\", original_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lance_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
